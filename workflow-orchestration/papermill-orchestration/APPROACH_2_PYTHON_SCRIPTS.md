# Approach 2: Pure Python Scripts (Recommended)

This is the **recommended approach** for most use cases. Direct Python execution without Papermill overhead.

## ğŸ¯ Why This Approach?

- âš¡ **37% faster** than Papermill (~25 seconds vs 40 seconds)
- ğŸ‘ï¸ **100% output visibility** - See everything in terminal
- ğŸ”§ **Simple** - Just Python, no complex dependencies
- ğŸ› **Easy debugging** - Errors shown immediately
- ğŸš€ **Production ready** - Built for deployment
- ğŸ”€ **Easy integration** - Standard subprocess calls
- ğŸ“Š **Scalable** - Works on distributed systems

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execution (Choose One):                                       â”‚
â”‚                                                              â”‚
â”‚ Sequential:                  Parallel:                       â”‚
â”‚ â”œâ”€ Load Data                 â”œâ”€ Data Prep (sequential)      â”‚
â”‚ â”œâ”€ Preprocess                â”œâ”€ Model 1 Training           â”‚
â”‚ â”œâ”€ Train Single Model        â”œâ”€ Model 2 Training  â” Parallelâ”‚
â”‚ â””â”€ Evaluate                  â”œâ”€ Model 3 Training  â”‚        â”‚
â”‚                              â”œâ”€ Model 4 Training  â”˜        â”‚
â”‚                              â””â”€ Model 5 Training           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Output Files:                                                 â”‚
â”‚ â”œâ”€ CSV files (data, predictions)                            â”‚
â”‚ â”œâ”€ PKL files (trained models)                               â”‚
â”‚ â”œâ”€ JSON files (metrics, evaluation)                         â”‚
â”‚ â””â”€ PNG files (visualizations)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start (90 seconds)

```bash
# Sequential execution (recommended first run)
python run_sequential_scripts.py
```

That's it! All output visible in terminal. Results in `outputs/`.

---

## ğŸ“– How to Use

### 1. Sequential Execution (Recommended)

Execute all pipeline steps in order:

```bash
python run_sequential_scripts.py
```

**Output in terminal:**
```
================================================================================
SEQUENTIAL PIPELINE RUNNER - PYTHON SCRIPTS VERSION
================================================================================

STEP 1: LOAD DATA
======================================================================

Loading data with parameters:
  - dataset: synthetic
  - test_size: 0.2
  - random_state: 42
  - output_dir: outputs

Generating synthetic regression dataset...
Dataset shape: (500, 11)

First few rows:
   feature_0  feature_1  feature_2  ... target
0   1.024063   2.061504   2.558199  ... 444.527556

Step 1 completed in 5.60 seconds

STEP 2: PREPROCESS DATA
======================================================================

Preprocessing with parameters:
  - normalize: true
  - scaler: StandardScaler

Step 2 completed in 4.87 seconds

STEP 3: TRAIN MODEL
======================================================================

Model: linear_regression
Training metrics:
  - MSE: 365.3829
  - RMSE: 19.1150
  - MAE: 14.7778
  - RÂ²: 0.9831

Step 3 completed in 4.48 seconds

STEP 4: EVALUATE MODEL
======================================================================

Evaluation metrics:
  - Test MSE: 388.3967
  - Test RMSE: 19.7078
  - Test RÂ²: 0.9804

Plots generated:
  âœ“ actual_vs_predicted.png
  âœ“ residuals.png
  âœ“ residuals_distribution.png
  âœ“ prediction_errors.png

Step 4 completed in 10.09 seconds

================================================================================
PIPELINE EXECUTION SUMMARY
================================================================================
Step 1: 01_load_data.py (5.60s) - SUCCESS
Step 2: 02_preprocess_data.py (4.87s) - SUCCESS
Step 3: 03_train_model.py (4.48s) - SUCCESS
Step 4: 04_evaluate_model.py (10.09s) - SUCCESS

Total Execution Time: 25.04 seconds

PIPELINE COMPLETED SUCCESSFULLY
================================================================================

Output Files Generated:
  - Data: outputs/data/X_train.csv, X_test.csv, y_train.csv, y_test.csv
  - Processed: outputs/processed/X_train_processed.csv, X_test_processed.csv
  - Models: outputs/models/linear_regression_model.pkl
  - Predictions: outputs/predictions/linear_regression_train_predictions.csv
  - Plots: outputs/plots/linear_regression_*.png (4 plots)
  - Metrics: outputs/models/linear_regression_*.json (3 files)
```

**Time:** ~25 seconds âœ“

### 2. Parallel Execution (5 Models)

Train multiple model configurations in parallel:

```bash
python run_parallel_scripts.py
```

**What it does:**
1. Loads data (once)
2. Preprocesses data (once)
3. Trains 5 different models **in parallel**:
   - Linear Regression
   - Ridge (Î±=0.1)
   - Ridge (Î±=1.0)
   - Ridge (Î±=10.0)
   - Lasso (Î±=0.1)
4. Evaluates all models **in parallel**

**Output:**
```
================================================================================
PARALLEL PIPELINE RUNNER - TRAINING 5 MODELS
================================================================================

Step 1-2: Preparing Data
  - Loading data...
  - Preprocessing...
Data preparation completed in 9.93 seconds

Step 3: Training 5 Models in Parallel...
  - Model 1/5: linear_regression... DONE (4.45s)
  - Model 2/5: ridge (alpha=0.1)... DONE (4.42s)
  - Model 3/5: ridge (alpha=1.0)... DONE (4.48s)
  - Model 4/5: ridge (alpha=10.0)... DONE (4.51s)
  - Model 5/5: lasso (alpha=0.1)... DONE (4.39s)
All models trained in 12.70 seconds

Step 4: Evaluating 5 Models in Parallel...
  - Model 1/5: linear_regression evaluation... DONE
  - Model 2/5: ridge (alpha=0.1) evaluation... DONE
  - Model 3/5: ridge (alpha=1.0) evaluation... DONE
  - Model 4/5: ridge (alpha=10.0) evaluation... DONE
  - Model 5/5: lasso (alpha=0.1) evaluation... DONE
All models evaluated in 21.71 seconds

================================================================================
RESULTS SUMMARY
================================================================================
Training Results: 5/5 successful
Training Time: 12.70 seconds
Evaluation Time: 21.71 seconds
Total Time: 34.41 seconds

Model Comparison:
1. linear_regression   - Train RÂ²: 0.9831, Test RÂ²: 0.9804
2. ridge (Î±=0.1)       - Train RÂ²: 0.9830, Test RÂ²: 0.9803
3. ridge (Î±=1.0)       - Train RÂ²: 0.9829, Test RÂ²: 0.9802
4. ridge (Î±=10.0)      - Train RÂ²: 0.9809, Test RÂ²: 0.9781
5. lasso (Î±=0.1)       - Train RÂ²: 0.9830, Test RÂ²: 0.9803

BEST MODEL: linear_regression (Test RÂ²: 0.9804)
================================================================================
```

**Time:** ~35 seconds (5 models trained in parallel) âœ“

---

## ğŸ® Command-Line Usage

Each step can be run individually with custom parameters:

### Step 1: Load Data

```bash
python scripts/01_load_data.py [test_size] [random_state] [dataset] [output_dir]
```

**Parameters:**
- `test_size`: Train/test split ratio (0.0-1.0, default: 0.2)
- `random_state`: Random seed for reproducibility (default: 42)
- `dataset`: Data source - "synthetic" (default) or path to CSV
- `output_dir`: Where to save data (default: outputs)

**Examples:**
```bash
# Default (20% test, synthetic data)
python scripts/01_load_data.py 0.2 42 synthetic outputs

# 30% test set
python scripts/01_load_data.py 0.3 42 synthetic outputs

# 70/30 split with different seed
python scripts/01_load_data.py 0.3 123 synthetic outputs

# Your own CSV file
python scripts/01_load_data.py 0.2 42 /path/to/data.csv outputs
```

### Step 2: Preprocess Data

```bash
python scripts/02_preprocess_data.py [normalize] [data_dir] [output_dir]
```

**Parameters:**
- `normalize`: Apply StandardScaler (true/false, default: true)
- `data_dir`: Where to load data from (default: outputs/data)
- `output_dir`: Where to save processed data (default: outputs)

**Examples:**
```bash
# Default (with normalization)
python scripts/02_preprocess_data.py true outputs/data outputs/processed

# Without normalization
python scripts/02_preprocess_data.py false outputs/data outputs/processed
```

### Step 3: Train Model

```bash
python scripts/03_train_model.py [model_type] [alpha] [fit_intercept] [data_dir] [output_dir]
```

**Parameters:**
- `model_type`: "linear_regression", "ridge", or "lasso"
- `alpha`: Regularization strength (default: 1.0, ignored for linear_regression)
- `fit_intercept`: Fit intercept term (true/false, default: true)
- `data_dir`: Where to load processed data (default: outputs/processed)
- `output_dir`: Where to save model (default: outputs)

**Examples:**
```bash
# Linear Regression
python scripts/03_train_model.py linear_regression 1.0 true outputs/processed outputs

# Ridge with alpha=0.5
python scripts/03_train_model.py ridge 0.5 true outputs/processed outputs

# Ridge with alpha=10.0
python scripts/03_train_model.py ridge 10.0 true outputs/processed outputs

# Lasso with alpha=0.1
python scripts/03_train_model.py lasso 0.1 true outputs/processed outputs
```

### Step 4: Evaluate Model

```bash
python scripts/04_evaluate_model.py [model_type] [data_dir] [model_dir] [output_dir] [generate_plots]
```

**Parameters:**
- `model_type`: Model to evaluate ("linear_regression", "ridge", "lasso")
- `data_dir`: Where to load processed data
- `model_dir`: Where to load trained model
- `output_dir`: Where to save evaluation results
- `generate_plots`: Create visualizations (true/false)

**Examples:**
```bash
# Full evaluation with plots
python scripts/04_evaluate_model.py linear_regression outputs/processed outputs/models outputs true

# Evaluation without plots
python scripts/04_evaluate_model.py ridge outputs/processed outputs/models outputs false
```

---

## ğŸ“Š Output Structure

All outputs saved to `outputs/` directory:

```
outputs/
â”‚
â”œâ”€â”€ data/                                 # Step 1: Raw data
â”‚   â”œâ”€â”€ X_train.csv                      # Training features (400 rows)
â”‚   â”œâ”€â”€ X_test.csv                       # Test features (100 rows)
â”‚   â”œâ”€â”€ y_train.csv                      # Training targets
â”‚   â”œâ”€â”€ y_test.csv                       # Test targets
â”‚   â””â”€â”€ metadata.json                    # Dataset info
â”‚
â”œâ”€â”€ processed/                           # Step 2: Preprocessed data
â”‚   â”œâ”€â”€ X_train_processed.csv           # Normalized training features
â”‚   â”œâ”€â”€ X_test_processed.csv            # Normalized test features
â”‚   â”œâ”€â”€ y_train.csv                     # Training targets (unchanged)
â”‚   â”œâ”€â”€ y_test.csv                      # Test targets (unchanged)
â”‚   â”œâ”€â”€ scaler.pkl                      # StandardScaler object
â”‚   â””â”€â”€ preprocessing_metadata.json     # Preprocessing details
â”‚
â”œâ”€â”€ models/                              # Step 3: Trained models
â”‚   â”œâ”€â”€ linear_regression_model.pkl     # Model file
â”‚   â”œâ”€â”€ linear_regression_metrics.json  # Training metrics
â”‚   â”œâ”€â”€ linear_regression_evaluation.json
â”‚   â””â”€â”€ linear_regression_evaluation_summary.json
â”‚
â”œâ”€â”€ predictions/                         # Step 3: Model predictions
â”‚   â”œâ”€â”€ linear_regression_train_predictions.csv
â”‚   â””â”€â”€ linear_regression_test_predictions.csv
â”‚
â””â”€â”€ plots/                               # Step 4: Visualizations
    â”œâ”€â”€ linear_regression_actual_vs_predicted_train.png
    â”œâ”€â”€ linear_regression_actual_vs_predicted_test.png
    â”œâ”€â”€ linear_regression_residuals.png
    â”œâ”€â”€ linear_regression_residuals_distribution.png
    â””â”€â”€ linear_regression_prediction_errors.png
```

---

## ğŸ“ˆ Example Metrics

### metrics.json (Training Results)
```json
{
  "model_type": "linear_regression",
  "fit_intercept": true,
  "train_metrics": {
    "mse": 365.3829,
    "rmse": 19.1150,
    "mae": 14.7778,
    "r2": 0.9831
  },
  "test_metrics": {
    "mse": 388.3967,
    "rmse": 19.7078,
    "mae": 15.2234,
    "r2": 0.9804
  }
}
```

### evaluation.json (Test Metrics with Details)
```json
{
  "model_type": "linear_regression",
  "test_metrics": {
    "mse": 388.3967,
    "rmse": 19.7078,
    "mae": 15.2234,
    "r2": 0.9804,
    "mean_absolute_percentage_error": 8.2345
  },
  "residuals": {
    "mean": 0.1234,
    "std": 18.9876,
    "min": -45.678,
    "max": 52.345
  }
}
```

---

## ğŸ”„ Common Workflows

### Workflow 1: Compare Two Models

```bash
# Train Linear Regression
python scripts/03_train_model.py linear_regression 1.0 true outputs/processed outputs
python scripts/04_evaluate_model.py linear_regression outputs/processed outputs/models outputs true

# Train Ridge
python scripts/03_train_model.py ridge 1.0 true outputs/processed outputs
python scripts/04_evaluate_model.py ridge outputs/processed outputs/models outputs true

# Compare plots
# Open: outputs/plots/linear_regression_*.png
# Open: outputs/plots/ridge_*.png
```

### Workflow 2: Hyperparameter Tuning

```bash
# Test different alpha values for Ridge
python scripts/03_train_model.py ridge 0.1 true outputs/processed outputs
python scripts/03_train_model.py ridge 1.0 true outputs/processed outputs
python scripts/03_train_model.py ridge 10.0 true outputs/processed outputs

# Compare metrics from JSON files
cat outputs/models/ridge_*_metrics.json
```

### Workflow 3: Different Train/Test Splits

```bash
# 80/20 split (default)
python scripts/01_load_data.py 0.2 42 synthetic outputs

# 70/30 split
python scripts/01_load_data.py 0.3 42 synthetic outputs

# 60/40 split
python scripts/01_load_data.py 0.4 42 synthetic outputs

# Train and compare results
python scripts/02_preprocess_data.py true outputs/data outputs/processed
python scripts/03_train_model.py linear_regression 1.0 true outputs/processed outputs
```

### Workflow 4: Using Your Own Data

```bash
# Prepare your CSV file with features and target:
# Format: first n columns = features, last column = target
# Example: feature_0, feature_1, ..., feature_9, target

# Load your data (replace .csv path)
python scripts/01_load_data.py 0.2 42 /path/to/your_data.csv outputs

# Continue with preprocessing and training
python scripts/02_preprocess_data.py true outputs/data outputs/processed
python scripts/03_train_model.py linear_regression 1.0 true outputs/processed outputs
python scripts/04_evaluate_model.py linear_regression outputs/processed outputs/models outputs true
```

---

## âš¡ Performance

### Execution Times
```
Single Model (Sequential):
  Step 1 (Load):        5.6s
  Step 2 (Preprocess):  4.9s
  Step 3 (Train):       4.5s
  Step 4 (Evaluate):   10.1s
  Total:              ~25 seconds

Multiple Models (Parallel):
  Data Prep:            9.9s (sequential)
  Training (5 models):  12.7s (parallel)
  Evaluation (5 models):21.7s (parallel)
  Total:              ~35 seconds

Linear Speedup: 5 models in 35s â‰ˆ 7s per model (not 23s sequential)
```

### Speedup vs Approach 1 (Papermill)
```
Sequential: 37% faster (25s vs 40s)
Parallel:   30% faster (35s vs 50s)
```

---

## âœ… Pros & Cons

### Advantages
âœ… **37% faster** than Papermill (25s vs 40s)
âœ… **100% output visibility** - All output in terminal
âœ… **Simple setup** - Just Python, no Papermill
âœ… **Easy debugging** - Immediate error messages
âœ… **Easy integration** - Standard subprocess calls
âœ… **Production ready** - Error handling & logging
âœ… **Scalable** - Works on distributed systems
âœ… **Version control** - Clean Python files

### Disadvantages
âŒ **No Jupyter interface** - Pure Python scripts
âŒ **Less visual** - No interactive environment
âŒ **Not ideal** for data exploration

---

## ğŸ› Troubleshooting

### Error: "ModuleNotFoundError: No module named 'sklearn'"
**Solution:**
```bash
pip install -r requirements.txt
```

### Error: "FileNotFoundError: outputs/data/X_train.csv not found"
**Solution:** Run Step 1 first:
```bash
python scripts/01_load_data.py 0.2 42 synthetic outputs
```

### Error: "No such file or directory: /outputs/models/model.pkl"
**Solution:** Run Step 3 first:
```bash
python scripts/03_train_model.py linear_regression 1.0 true outputs/processed outputs
```

### Output files not being created
**Solution:** Check terminal for error messages. All errors are printed there.

### Windows path errors
**Solution:** The scripts handle Windows paths automatically. Use forward slashes or just use the defaults.

---

## ğŸ¯ When to Use This Approach

Use **Approach 2 (Python Scripts)** when:
- âœ… You need **fast execution**
- âœ… You need **real-time output visibility**
- âœ… You're building **production pipelines**
- âœ… You need **easy debugging**
- âœ… You want **simple orchestration**
- âœ… You prefer **Python over notebooks**
- âœ… You need **CI/CD integration**
- âœ… You want **easy scaling**

---

## ğŸ“ Learning Path

1. **Basic:** Run `python run_sequential_scripts.py`
2. **Explore:** Review output files in `outputs/`
3. **Customize:** Modify parameters and run individual scripts
4. **Integrate:** Use in your own systems
5. **Extend:** Modify scripts to add new models

---

## ğŸ“ Next Steps

1. **Run:** `python run_sequential_scripts.py`
2. **Explore:** Check `outputs/` folder
3. **Customize:** Try different parameters
4. **Integrate:** Use in your systems
5. **Extend:** Add your own models

---

## ğŸ“š Related Docs

- **README.md** - Overview and comparison
- **GETTING_STARTED.md** - Installation
- **APPROACH_1_PAPERMILL.md** - Alternative approach

---

**Ready?** Run:
```bash
python run_sequential_scripts.py
```
