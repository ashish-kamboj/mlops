{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a6ad727-2f75-4d96-86d0-29bd9dfbe2fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evidently==0.7.19 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (0.7.19)\n",
      "Requirement already satisfied: pyyaml==6.0.2 in /databricks/python3/lib/python3.12/site-packages (6.0.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in /databricks/python3/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy==2.2.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (2.2.1)\n",
      "Requirement already satisfied: azure-storage-file-datalake==12.20.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (12.20.0)\n",
      "Requirement already satisfied: azure-identity==1.19.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (1.19.0)\n",
      "Requirement already satisfied: plotly==5.24.1 in /databricks/python3/lib/python3.12/site-packages (5.24.1)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /databricks/python3/lib/python3.12/site-packages (from evidently==0.7.19) (2025.1.31)\n",
      "Requirement already satisfied: cryptography>=43.0.1 in /databricks/python3/lib/python3.12/site-packages (from evidently==0.7.19) (43.0.3)\n",
      "Requirement already satisfied: deprecation>=2.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from evidently==0.7.19) (2.1.0)\n",
      "Requirement already satisfied: dynaconf>=3.2.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from evidently==0.7.19) (3.2.12)\n",
      "Requirement already satisfied: fsspec>=2024.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from evidently==0.7.19) (2026.1.0)\n",
      "Requirement already satisfied: iterative-telemetry>=0.0.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from evidently==0.7.19) (0.0.10)\n",
      "Requirement already satisfied: litestar>=2.19.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from evidently==0.7.19) (2.19.0)\n",
      "Requirement already satisfied: nltk>=3.6.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from evidently==0.7.19) (3.9.2)\n",
      "Requirement already satisfied: opentelemetry-proto>=1.25.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from evidently==0.7.19) (1.39.1)\n",
      "Requirement already satisfied: pydantic>=1.10.16 in /databricks/python3/lib/python3.12/site-packages (from evidently==0.7.19) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.32.0 in /databricks/python3/lib/python3.12/site-packages (from evidently==0.7.19) (2.32.3)\n",
      "Requirement already satisfied: rich>=13 in /databricks/python3/lib/python3.12/site-packages (from evidently==0.7.19) (13.9.4)\n",
      "Requirement already satisfied: scikit-learn>=1.1.1 in /databricks/python3/lib/python3.12/site-packages (from evidently==0.7.19) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /databricks/python3/lib/python3.12/site-packages (from evidently==0.7.19) (1.15.1)\n",
      "Requirement already satisfied: statsmodels>=0.12.2 in /databricks/python3/lib/python3.12/site-packages (from evidently==0.7.19) (0.14.4)\n",
      "Requirement already satisfied: typer>=0.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from evidently==0.7.19) (0.21.1)\n",
      "Requirement already satisfied: typing-inspect>=0.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from evidently==0.7.19) (0.9.0)\n",
      "Requirement already satisfied: ujson>=5.4.0 in /databricks/python3/lib/python3.12/site-packages (from evidently==0.7.19) (5.10.0)\n",
      "Requirement already satisfied: urllib3>=1.26.19 in /databricks/python3/lib/python3.12/site-packages (from evidently==0.7.19) (2.3.0)\n",
      "Requirement already satisfied: uuid6>=2024.7.10 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from evidently==0.7.19) (2025.0.1)\n",
      "Requirement already satisfied: uvicorn>=0.22.0 in /databricks/python3/lib/python3.12/site-packages (from uvicorn[standard]>=0.22.0->evidently==0.7.19) (0.34.2)\n",
      "Requirement already satisfied: watchdog>=3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from evidently==0.7.19) (6.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /databricks/python3/lib/python3.12/site-packages (from pandas==2.2.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas==2.2.3) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /databricks/python3/lib/python3.12/site-packages (from pandas==2.2.3) (2024.1)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in /databricks/python3/lib/python3.12/site-packages (from azure-storage-file-datalake==12.20.0) (1.34.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.25.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from azure-storage-file-datalake==12.20.0) (12.28.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /databricks/python3/lib/python3.12/site-packages (from azure-storage-file-datalake==12.20.0) (4.12.2)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /databricks/python3/lib/python3.12/site-packages (from azure-storage-file-datalake==12.20.0) (0.6.1)\n",
      "Requirement already satisfied: msal>=1.30.0 in /databricks/python3/lib/python3.12/site-packages (from azure-identity==1.19.0) (1.32.3)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from azure-identity==1.19.0) (1.3.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /databricks/python3/lib/python3.12/site-packages (from plotly==5.24.1) (9.0.0)\n",
      "Requirement already satisfied: packaging in /databricks/python3/lib/python3.12/site-packages (from plotly==5.24.1) (24.1)\n",
      "Requirement already satisfied: six>=1.11.0 in /usr/lib/python3/dist-packages (from azure-core>=1.30.0->azure-storage-file-datalake==12.20.0) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.12/site-packages (from cryptography>=43.0.1->evidently==0.7.19) (1.17.1)\n",
      "Requirement already satisfied: appdirs in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from iterative-telemetry>=0.0.5->evidently==0.7.19) (1.4.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from iterative-telemetry>=0.0.5->evidently==0.7.19) (3.18.0)\n",
      "Requirement already satisfied: distro in /usr/lib/python3/dist-packages (from iterative-telemetry>=0.0.5->evidently==0.7.19) (1.9.0)\n",
      "Requirement already satisfied: anyio>=3 in /databricks/python3/lib/python3.12/site-packages (from litestar>=2.19.0->evidently==0.7.19) (4.6.2)\n",
      "Requirement already satisfied: click in /databricks/python3/lib/python3.12/site-packages (from litestar>=2.19.0->evidently==0.7.19) (8.1.7)\n",
      "Requirement already satisfied: httpx>=0.22 in /databricks/python3/lib/python3.12/site-packages (from litestar>=2.19.0->evidently==0.7.19) (0.27.0)\n",
      "Requirement already satisfied: litestar-htmx>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from litestar>=2.19.0->evidently==0.7.19) (0.5.0)\n",
      "Requirement already satisfied: msgspec>=0.18.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from litestar>=2.19.0->evidently==0.7.19) (0.20.0)\n",
      "Requirement already satisfied: multidict>=6.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from litestar>=2.19.0->evidently==0.7.19) (6.7.0)\n",
      "Requirement already satisfied: multipart>=1.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from litestar>=2.19.0->evidently==0.7.19) (1.3.0)\n",
      "Requirement already satisfied: polyfactory>=2.6.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from litestar>=2.19.0->evidently==0.7.19) (3.2.0)\n",
      "Requirement already satisfied: rich-click in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from litestar>=2.19.0->evidently==0.7.19) (1.9.5)\n",
      "Requirement already satisfied: sniffio>=1.3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from litestar>=2.19.0->evidently==0.7.19) (1.3.1)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /databricks/python3/lib/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity==1.19.0) (2.10.1)\n",
      "Requirement already satisfied: joblib in /databricks/python3/lib/python3.12/site-packages (from nltk>=3.6.7->evidently==0.7.19) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from nltk>=3.6.7->evidently==0.7.19) (2026.1.15)\n",
      "Requirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from nltk>=3.6.7->evidently==0.7.19) (4.67.1)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-proto>=1.25.0->evidently==0.7.19) (5.29.4)\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in /databricks/python3/lib/python3.12/site-packages (from pandas[parquet]>=1.3.5->evidently==0.7.19) (19.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic>=1.10.16->evidently==0.7.19) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /databricks/python3/lib/python3.12/site-packages (from pydantic>=1.10.16->evidently==0.7.19) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.32.0->evidently==0.7.19) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.32.0->evidently==0.7.19) (3.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /databricks/python3/lib/python3.12/site-packages (from rich>=13->evidently==0.7.19) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /databricks/python3/lib/python3.12/site-packages (from rich>=13->evidently==0.7.19) (2.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn>=1.1.1->evidently==0.7.19) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /databricks/python3/lib/python3.12/site-packages (from statsmodels>=0.12.2->evidently==0.7.19) (1.0.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from typer>=0.3->evidently==0.7.19) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.12/site-packages (from typing-inspect>=0.9.0->evidently==0.7.19) (1.0.0)\n",
      "Requirement already satisfied: h11>=0.8 in /databricks/python3/lib/python3.12/site-packages (from uvicorn>=0.22.0->uvicorn[standard]>=0.22.0->evidently==0.7.19) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from uvicorn[standard]>=0.22.0->evidently==0.7.19) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from uvicorn[standard]>=0.22.0->evidently==0.7.19) (1.2.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from uvicorn[standard]>=0.22.0->evidently==0.7.19) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from uvicorn[standard]>=0.22.0->evidently==0.7.19) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from uvicorn[standard]>=0.22.0->evidently==0.7.19) (16.0)\n",
      "Requirement already satisfied: pycparser in /databricks/python3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=43.0.1->evidently==0.7.19) (2.21)\n",
      "Requirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.12/site-packages (from httpx>=0.22->litestar>=2.19.0->evidently==0.7.19) (1.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /databricks/python3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=13->evidently==0.7.19) (0.1.0)\n",
      "Requirement already satisfied: faker>=5.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c055cb1f-4f4c-44af-9745-170f66a1b3d1/lib/python3.12/site-packages (from polyfactory>=2.6.3->litestar>=2.19.0->evidently==0.7.19) (40.1.2)\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Packages installed successfully\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run only once)\n",
    "%pip install evidently==0.7.19 pyyaml==6.0.2 pandas==2.2.3 numpy==2.2.1 azure-storage-file-datalake==12.20.0 azure-identity==1.19.0 plotly==5.24.1\n",
    "\n",
    "print(\"Packages installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97022d32-979d-47cf-93fb-9b0ea61440cd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import required libraries"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add utils to path (adjust path as needed for Databricks)\n",
    "sys.path.append('/Workspace/Users/<<USER_ID>>/data-drift-evidently-ai')\n",
    "sys.path.append(str(Path.cwd().parent))  # For local testing\n",
    "\n",
    "# Import custom utilities\n",
    "from utils import ConfigManager, DriftDetector, ReportManager, DataLoader, setup_logger\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a06cf333-7f40-4132-ace8-20d870db1534",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeb15554-3bb7-4954-9d0b-c8ba63be6bf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Configuration loaded successfully\n",
      "  - Catalog: data_catalog\n",
      "  - Schema: outputs\n",
      "  - Tables to monitor: 3\n"
     ]
    }
   ],
   "source": [
    "# Configuration file path (adjust as needed)\n",
    "CONFIG_PATH = '../config/drift_config.yaml'\n",
    "\n",
    "# For Databricks, use dbutils to work with workspace files\n",
    "# CONFIG_PATH = '/Workspace/Repos/<your-repo>/data-drift-evidently-ai/config/drift_config.yaml'\n",
    "\n",
    "# Initialize configuration manager\n",
    "try:\n",
    "    config = ConfigManager(CONFIG_PATH)\n",
    "    print(\"âœ“ Configuration loaded successfully\")\n",
    "    print(f\"  - Catalog: {config.get_catalog_name()}\")\n",
    "    print(f\"  - Schema: {config.get_schema_name()}\")\n",
    "    print(f\"  - Tables to monitor: {len(config.get_tables())}\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error loading configuration: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1fa7b00-0e48-4f6c-a2db-3578e3f91ba1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - ================================================================================\n",
      "INFO - Data Drift Detection - Python Version\n",
      "INFO - ================================================================================\n",
      "INFO - Configuration loaded from: ../config/drift_config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "logger = setup_logger(\n",
    "    log_level=config.get_log_level(),\n",
    "    logger_name='data_drift',\n",
    "    adls_config=config.get_adls_config() if config.is_adls_output_enabled() else None\n",
    ")\n",
    "\n",
    "logger.info(\"=\"*80)\n",
    "logger.info(\"Data Drift Detection - Python Version\")\n",
    "logger.info(\"=\"*80)\n",
    "logger.info(f\"Configuration loaded from: {CONFIG_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2debdccd-c57c-4477-9a9b-68166ecacb98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "237d6482-20b4-40fe-9e3e-d97bdd71a81b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - âœ“ Drift detector initialized\n",
      "INFO - âœ“ Report manager initialized\n",
      "INFO - âœ“ Data loader initialized\n",
      "\n",
      "âœ“ All components initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize drift detector\n",
    "drift_detector = DriftDetector(config)\n",
    "logger.info(\"âœ“ Drift detector initialized\")\n",
    "\n",
    "# Initialize report manager\n",
    "report_manager = ReportManager(config)\n",
    "logger.info(\"âœ“ Report manager initialized\")\n",
    "\n",
    "# Initialize data loader (without Spark for Python version)\n",
    "data_loader = DataLoader(config, spark=spark)  # Pass spark session from Databricks\n",
    "logger.info(\"âœ“ Data loader initialized\")\n",
    "\n",
    "print(\"\\nâœ“ All components initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6328784e-5f2b-4e1f-a40b-c5d8ed643b3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Process Each Table\n",
    "\n",
    "Loop through configured tables and detect drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "251d3401-1e8c-4330-a533-8b187088c45a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 3 tables for drift detection...\n",
      "================================================================================\n",
      "INFO - \n",
      "================================================================================\n",
      "INFO - Processing table 1/3: customer_data\n",
      "INFO - ================================================================================\n",
      "INFO - Loading data for table: customer_data\n",
      "Comparing UC versions: 2 (reference) vs 3 (current)\n",
      "INFO - Data loaded - Reference: 10000 rows, Current: 10000 rows\n",
      "INFO - Running drift detection...\n",
      "WARNING - âš ï¸  DRIFT DETECTED in customer_data\n",
      "WARNING -    Drifted columns: ['income', 'age', 'credit_score', 'data_version', 'account_type', 'region']\n",
      "INFO -    Total columns: 9\n",
      "INFO -    Drifted columns: 6\n",
      "INFO -    Drift share: 75.00%\n",
      "INFO - Saving reports for customer_data...\n",
      "INFO -    local_html: /Workspace/Users/ashu.009kamboj@gmail.com/data-drift-evidently-ai/reports/html/customer_data_20260120_165052_drift_report.html\n",
      "INFO -    local_json: /Workspace/Users/ashu.009kamboj@gmail.com/data-drift-evidently-ai/reports/json/customer_data_20260120_165052_drift_report.json\n",
      "\n",
      "âœ“ Completed: customer_data\n",
      "  âš ï¸  DRIFT DETECTED (6 columns)\n",
      "--------------------------------------------------------------------------------\n",
      "INFO - \n",
      "================================================================================\n",
      "INFO - Processing table 2/3: product_sales\n",
      "INFO - ================================================================================\n",
      "INFO - Loading data for table: product_sales\n",
      "Comparing UC versions: 2 (reference) vs 3 (current)\n",
      "INFO - Data loaded - Reference: 50000 rows, Current: 50000 rows\n",
      "INFO - Running drift detection...\n",
      "WARNING - âš ï¸  DRIFT DETECTED in product_sales\n",
      "WARNING -    Drifted columns: ['revenue', 'price', 'product_category']\n",
      "INFO -    Total columns: 4\n",
      "INFO -    Drifted columns: 3\n",
      "INFO -    Drift share: 75.00%\n",
      "INFO - Saving reports for product_sales...\n",
      "INFO -    local_html: /Workspace/Users/ashu.009kamboj@gmail.com/data-drift-evidently-ai/reports/html/product_sales_20260120_165059_drift_report.html\n",
      "INFO -    local_json: /Workspace/Users/ashu.009kamboj@gmail.com/data-drift-evidently-ai/reports/json/product_sales_20260120_165059_drift_report.json\n",
      "\n",
      "âœ“ Completed: product_sales\n",
      "  âš ï¸  DRIFT DETECTED (3 columns)\n",
      "--------------------------------------------------------------------------------\n",
      "INFO - \n",
      "================================================================================\n",
      "INFO - Processing table 3/3: user_behavior\n",
      "INFO - ================================================================================\n",
      "INFO - Loading data for table: user_behavior\n",
      "Comparing UC versions: 2 (reference) vs 3 (current)\n",
      "INFO - Data loaded - Reference: 30000 rows, Current: 30000 rows\n",
      "INFO - Running drift detection...\n",
      "WARNING - âš ï¸  DRIFT DETECTED in user_behavior\n",
      "WARNING -    Drifted columns: ['session_duration_minutes', 'pages_viewed', 'device_type', 'data_version', 'traffic_source']\n",
      "INFO -    Total columns: 9\n",
      "INFO -    Drifted columns: 5\n",
      "INFO -    Drift share: 62.50%\n",
      "INFO - Saving reports for user_behavior...\n",
      "INFO -    local_html: /Workspace/Users/ashu.009kamboj@gmail.com/data-drift-evidently-ai/reports/html/user_behavior_20260120_165107_drift_report.html\n",
      "INFO -    local_json: /Workspace/Users/ashu.009kamboj@gmail.com/data-drift-evidently-ai/reports/json/user_behavior_20260120_165107_drift_report.json\n",
      "\n",
      "âœ“ Completed: user_behavior\n",
      "  âš ï¸  DRIFT DETECTED (5 columns)\n",
      "--------------------------------------------------------------------------------\n",
      "INFO - \n",
      "================================================================================\n",
      "INFO - Drift detection completed for all tables\n",
      "INFO - ================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Get list of tables from configuration\n",
    "tables = config.get_tables()\n",
    "results_summary = []\n",
    "\n",
    "print(f\"\\nProcessing {len(tables)} tables for drift detection...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, table_config in enumerate(tables, 1):\n",
    "    table_name = table_config['name']\n",
    "    columns = table_config.get('columns', 'all')\n",
    "    \n",
    "    logger.info(f\"\\n{'='*80}\")\n",
    "    logger.info(f\"Processing table {idx}/{len(tables)}: {table_name}\")\n",
    "    logger.info(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        # Load data versions\n",
    "        logger.info(f\"Loading data for table: {table_name}\")\n",
    "        reference_data, current_data = data_loader.load_table_versions(\n",
    "            table_name=table_name,\n",
    "            use_spark=True  # Using Spark to load from Unity Catalog\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Data loaded - Reference: {len(reference_data)} rows, Current: {len(current_data)} rows\")\n",
    "        \n",
    "        # Apply sampling if configured\n",
    "        reference_data = drift_detector.apply_sampling(reference_data)\n",
    "        current_data = drift_detector.apply_sampling(current_data)\n",
    "        \n",
    "        # Detect drift\n",
    "        logger.info(f\"Running drift detection...\")\n",
    "        report, drift_summary = drift_detector.detect_drift(\n",
    "            reference_data=reference_data,\n",
    "            current_data=current_data,\n",
    "            table_name=table_name,\n",
    "            columns=columns if columns != 'all' else None,\n",
    "        )\n",
    "        \n",
    "        # Log drift results\n",
    "        if drift_summary['dataset_drift']:\n",
    "            logger.warning(f\"âš ï¸  DRIFT DETECTED in {table_name}\")\n",
    "            logger.warning(f\"   Drifted columns: {drift_summary['drifted_columns']}\")\n",
    "        else:\n",
    "            logger.info(f\"âœ“ No significant drift detected in {table_name}\")\n",
    "        \n",
    "        logger.info(f\"   Total columns: {drift_summary['num_columns']}\")\n",
    "        logger.info(f\"   Drifted columns: {drift_summary['num_drifted_columns']}\")\n",
    "        logger.info(f\"   Drift share: {drift_summary['drift_share']:.2%}\")\n",
    "        \n",
    "        # Save reports\n",
    "        logger.info(f\"Saving reports for {table_name}...\")\n",
    "        saved_paths = report_manager.save_reports(\n",
    "            report=report,\n",
    "            drift_summary=drift_summary,\n",
    "            table_name=table_name\n",
    "        )\n",
    "        \n",
    "        for report_type, path in saved_paths.items():\n",
    "            logger.info(f\"   {report_type}: {path}\")\n",
    "        \n",
    "        # Add to summary\n",
    "        results_summary.append({\n",
    "            'table_name': table_name,\n",
    "            'total_columns': drift_summary['num_columns'],\n",
    "            'drifted_columns': drift_summary['num_drifted_columns'],\n",
    "            'drift_share': drift_summary['drift_share'],\n",
    "            'dataset_drift': drift_summary['dataset_drift'],\n",
    "            'report_paths': saved_paths\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nâœ“ Completed: {table_name}\")\n",
    "        if drift_summary['dataset_drift']:\n",
    "            print(f\"  âš ï¸  DRIFT DETECTED ({drift_summary['num_drifted_columns']} columns)\")\n",
    "        else:\n",
    "            print(f\"  âœ“ No drift detected\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"âœ— Error processing table {table_name}: {e}\", exc_info=True)\n",
    "        print(f\"\\nâœ— Error processing {table_name}: {e}\")\n",
    "        results_summary.append({\n",
    "            'table_name': table_name,\n",
    "            'error': str(e)\n",
    "        })\n",
    "    \n",
    "    print(\"-\"*80)\n",
    "\n",
    "logger.info(\"\\n\" + \"=\"*80)\n",
    "logger.info(\"Drift detection completed for all tables\")\n",
    "logger.info(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4590eb7-8628-4125-afb8-0462e2ec7afc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'table_name': 'customer_data',\n",
       "  'total_columns': 9,\n",
       "  'drifted_columns': 6,\n",
       "  'drift_share': 0.75,\n",
       "  'dataset_drift': True,\n",
       "  'report_paths': {'local_html': '/Workspace/Users/ashu.009kamboj@gmail.com/data-drift-evidently-ai/reports/html/customer_data_20260120_165052_drift_report.html',\n",
       "   'local_json': '/Workspace/Users/ashu.009kamboj@gmail.com/data-drift-evidently-ai/reports/json/customer_data_20260120_165052_drift_report.json'}},\n",
       " {'table_name': 'product_sales',\n",
       "  'total_columns': 4,\n",
       "  'drifted_columns': 3,\n",
       "  'drift_share': 0.75,\n",
       "  'dataset_drift': True,\n",
       "  'report_paths': {'local_html': '/Workspace/Users/ashu.009kamboj@gmail.com/data-drift-evidently-ai/reports/html/product_sales_20260120_165059_drift_report.html',\n",
       "   'local_json': '/Workspace/Users/ashu.009kamboj@gmail.com/data-drift-evidently-ai/reports/json/product_sales_20260120_165059_drift_report.json'}},\n",
       " {'table_name': 'user_behavior',\n",
       "  'total_columns': 9,\n",
       "  'drifted_columns': 5,\n",
       "  'drift_share': 0.625,\n",
       "  'dataset_drift': True,\n",
       "  'report_paths': {'local_html': '/Workspace/Users/ashu.009kamboj@gmail.com/data-drift-evidently-ai/reports/html/user_behavior_20260120_165107_drift_report.html',\n",
       "   'local_json': '/Workspace/Users/ashu.009kamboj@gmail.com/data-drift-evidently-ai/reports/json/user_behavior_20260120_165107_drift_report.json'}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4d9edaa-ae87-41b9-abe8-3e10a46c4234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary Report\n",
    "\n",
    "Display overall drift detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11c8279d-325d-469b-aa0b-c6b650b62dfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      table_name  ...                                       report_paths\n",
      "0  customer_data  ...  {'local_html': '/Workspace/Users/ashu.009kambo...\n",
      "1  product_sales  ...  {'local_html': '/Workspace/Users/ashu.009kambo...\n",
      "2  user_behavior  ...  {'local_html': '/Workspace/Users/ashu.009kambo...\n",
      "\n",
      "[3 rows x 6 columns]\n",
      "\n",
      "================================================================================\n",
      "DRIFT DETECTION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "âœ“ Successfully processed 3 tables\n",
      "\n",
      "        Table  Total Columns  Drifted Columns Drift Share   Status\n",
      "customer_data              9                6      75.00% âš ï¸ DRIFT\n",
      "product_sales              4                3      75.00% âš ï¸ DRIFT\n",
      "user_behavior              9                5      62.50% âš ï¸ DRIFT\n",
      "\n",
      "================================================================================\n",
      "Overall Statistics:\n",
      "  - Total tables processed: 3\n",
      "  - Tables with drift: 3\n",
      "  - Tables without drift: 0\n",
      "================================================================================\n",
      "\n",
      "To view reports, check the output locations:\n",
      "  Local: reports (HTML: reports/html, JSON: reports/json)\n"
     ]
    }
   ],
   "source": [
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame(results_summary)\n",
    "print(summary_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DRIFT DETECTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'error' in summary_df.columns:\n",
    "    # Show tables with errors\n",
    "    error_tables = summary_df[summary_df['error'].notna()]\n",
    "    if not error_tables.empty:\n",
    "        print(\"\\nâš ï¸  Tables with errors:\")\n",
    "        for _, row in error_tables.iterrows():\n",
    "            print(f\"  - {row['table_name']}: {row['error']}\")\n",
    "else:\n",
    "    # Ensure 'error' column exists (add it if missing)\n",
    "    summary_df['error'] = None  # or pd.NA\n",
    "\n",
    "# Show tables without errors\n",
    "success_df = summary_df[~summary_df['table_name'].isin(summary_df[summary_df.get('error', pd.Series()).notna()]['table_name'])]\n",
    "\n",
    "if not success_df.empty:\n",
    "    print(f\"\\nâœ“ Successfully processed {len(success_df)} tables\\n\")\n",
    "    \n",
    "    # Display summary table\n",
    "    display_df = success_df[['table_name', 'total_columns', 'drifted_columns', 'drift_share', 'dataset_drift']].copy()\n",
    "    display_df['drift_share'] = display_df['drift_share'].apply(lambda x: f\"{x:.2%}\")\n",
    "    display_df['drift_status'] = display_df['dataset_drift'].apply(lambda x: 'âš ï¸ DRIFT' if x else 'âœ“ OK')\n",
    "    display_df = display_df.drop('dataset_drift', axis=1)\n",
    "    display_df.columns = ['Table', 'Total Columns', 'Drifted Columns', 'Drift Share', 'Status']\n",
    "    \n",
    "    print(display_df.to_string(index=False))\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_drifted = display_df[display_df['Status'] == 'âš ï¸ DRIFT'].shape[0]\n",
    "    total_ok = display_df[display_df['Status'] == 'âœ“ OK'].shape[0]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Overall Statistics:\")\n",
    "    print(f\"  - Total tables processed: {len(display_df)}\")\n",
    "    print(f\"  - Tables with drift: {total_drifted}\")\n",
    "    print(f\"  - Tables without drift: {total_ok}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(\"To view reports, check the output locations:\")\n",
    "print(f\"  Local: reports (HTML: reports/html, JSON: reports/json)\")\n",
    "if config.is_adls_output_enabled():\n",
    "    adls_config = config.get_adls_config()\n",
    "    print(f\"  ADLS: {adls_config['container']}/{adls_config['base_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b33b179-d527-4c45-8445-0146d262f7bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## View Sample Report\n",
    "\n",
    "Display a sample drift report inline (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f60c8775-bb24-42c8-aeab-f6ff236ebd88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To view reports, check the output directories:\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to display HTML report inline in notebook\n",
    "# from IPython.display import HTML, display\n",
    "\n",
    "# if len(results_summary) > 0 and 'report_paths' in results_summary[0]:\n",
    "#     # Get first HTML report path\n",
    "#     for result in results_summary:\n",
    "#         if 'report_paths' in result:\n",
    "#             paths = result['report_paths']\n",
    "#             html_path = paths.get('local_html')\n",
    "#             if html_path and os.path.exists(html_path):\n",
    "#                 print(f\"Displaying report for: {result['table_name']}\")\n",
    "#                 with open(html_path, 'r', encoding='utf-8') as f:\n",
    "#                     html_content = f.read()\n",
    "#                 display(HTML(html_content))\n",
    "#                 break\n",
    "\n",
    "print(\"To view reports, check the output directories:\")\n",
    "if config.is_local_output_enabled():\n",
    "    print(f\"  Local: {config.get_local_output_path()}\")\n",
    "if config.is_adls_output_enabled():\n",
    "    adls_config = config.get_adls_config()\n",
    "    print(f\"  ADLS: {adls_config['container']}/{adls_config['base_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7c1e4d0-4822-49da-8782-830bf8e4f2e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "### Viewing Reports\n",
    "- **HTML Reports**: Open in browser for interactive visualization\n",
    "- **JSON Reports**: Use for programmatic analysis or integration with monitoring systems\n",
    "\n",
    "### Next Steps\n",
    "1. Review detailed reports for tables with detected drift\n",
    "2. Investigate root causes of drift in specific columns\n",
    "3. Adjust statistical test thresholds if needed in configuration\n",
    "4. Schedule this notebook to run periodically for continuous monitoring\n",
    "5. Set up alerting based on drift detection results\n",
    "\n",
    "### Configuration Tips\n",
    "- Adjust `column_drift_threshold` to control sensitivity\n",
    "- Add or remove statistical tests based on your data characteristics\n",
    "- Enable ADLS output for production use\n",
    "- Configure sampling for very large datasets"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_drift_detection_python",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
