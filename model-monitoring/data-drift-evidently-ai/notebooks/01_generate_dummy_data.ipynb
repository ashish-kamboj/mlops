{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4376829-8a8a-4654-a532-d28e61f2a2e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType, TimestampType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe1301b7-19e7-45ba-b52a-2b8087bc4f65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configuration\n",
    "Set up Unity Catalog details and table configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33123261-2e1b-40fd-baea-a157e06e0716",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Unity Catalog configuration\n",
    "CATALOG_NAME = \"data_catalog\"\n",
    "SCHEMA_NAME = \"outputs\"\n",
    "\n",
    "# # Create schema if it doesn't exist\n",
    "# spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG_NAME}\")\n",
    "# spark.sql(f\"USE CATALOG {CATALOG_NAME}\")\n",
    "# spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {SCHEMA_NAME}\")\n",
    "\n",
    "# print(f\"Using catalog: {CATALOG_NAME}.{SCHEMA_NAME}\")\n",
    "\n",
    "# Data generation parameters\n",
    "NUM_CUSTOMERS = 10000\n",
    "NUM_TRANSACTIONS = 50000\n",
    "NUM_USER_EVENTS = 30000\n",
    "\n",
    "# Random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "438d05be-174c-4dfc-a804-914d44ca17b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Helper Functions for Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aae5b588-e761-4a5e-b141-933011bfe0ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer data generation function created\n"
     ]
    }
   ],
   "source": [
    "def generate_customer_data(num_records, version, drift_level='none'):\n",
    "    \"\"\"\n",
    "    Generate customer data with optional drift.\n",
    "    \n",
    "    Args:\n",
    "        num_records: Number of customer records to generate\n",
    "        version: Version identifier (e.g., 'v1', 'v2')\n",
    "        drift_level: Level of drift ('none', 'low', 'medium', 'high')\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame with customer data\n",
    "    \"\"\"\n",
    "    # Base timestamp for this version\n",
    "    base_date = datetime.now() - timedelta(days=30 if version == 'v1' else 0)\n",
    "    \n",
    "    # Generate base data\n",
    "    customer_ids = [f\"CUST_{i:06d}\" for i in range(1, num_records + 1)]\n",
    "    \n",
    "    # Age distribution (introduce drift in v2)\n",
    "    if version == 'v1':\n",
    "        ages = np.random.normal(45, 15, num_records).astype(int)\n",
    "    else:\n",
    "        if drift_level == 'high':\n",
    "            # Shift younger in v2 (significant drift)\n",
    "            ages = np.random.normal(38, 12, num_records).astype(int)\n",
    "        elif drift_level == 'medium':\n",
    "            ages = np.random.normal(42, 14, num_records).astype(int)\n",
    "        else:\n",
    "            ages = np.random.normal(45, 15, num_records).astype(int)\n",
    "    \n",
    "    ages = np.clip(ages, 18, 90)\n",
    "    \n",
    "    # Income distribution (introduce drift)\n",
    "    if version == 'v1':\n",
    "        incomes = np.random.lognormal(10.5, 0.8, num_records)\n",
    "    else:\n",
    "        if drift_level == 'high':\n",
    "            # Higher income in v2\n",
    "            incomes = np.random.lognormal(10.8, 0.9, num_records)\n",
    "        elif drift_level == 'medium':\n",
    "            incomes = np.random.lognormal(10.6, 0.85, num_records)\n",
    "        else:\n",
    "            incomes = np.random.lognormal(10.5, 0.8, num_records)\n",
    "    \n",
    "    incomes = np.round(incomes, 2)\n",
    "    \n",
    "    # Region distribution (introduce drift)\n",
    "    if version == 'v1':\n",
    "        regions = np.random.choice(\n",
    "            ['North', 'South', 'East', 'West'],\n",
    "            num_records,\n",
    "            p=[0.3, 0.25, 0.25, 0.2]\n",
    "        )\n",
    "    else:\n",
    "        if drift_level == 'high':\n",
    "            # Different region distribution in v2\n",
    "            regions = np.random.choice(\n",
    "                ['North', 'South', 'East', 'West'],\n",
    "                num_records,\n",
    "                p=[0.2, 0.3, 0.15, 0.35]\n",
    "            )\n",
    "        elif drift_level == 'medium':\n",
    "            regions = np.random.choice(\n",
    "                ['North', 'South', 'East', 'West'],\n",
    "                num_records,\n",
    "                p=[0.25, 0.27, 0.23, 0.25]\n",
    "            )\n",
    "        else:\n",
    "            regions = np.random.choice(\n",
    "                ['North', 'South', 'East', 'West'],\n",
    "                num_records,\n",
    "                p=[0.3, 0.25, 0.25, 0.2]\n",
    "            )\n",
    "    \n",
    "    # Credit score (introduce drift)\n",
    "    if version == 'v1':\n",
    "        credit_scores = np.random.normal(680, 80, num_records).astype(int)\n",
    "    else:\n",
    "        if drift_level == 'high':\n",
    "            credit_scores = np.random.normal(710, 75, num_records).astype(int)\n",
    "        elif drift_level == 'medium':\n",
    "            credit_scores = np.random.normal(695, 78, num_records).astype(int)\n",
    "        else:\n",
    "            credit_scores = np.random.normal(680, 80, num_records).astype(int)\n",
    "    \n",
    "    credit_scores = np.clip(credit_scores, 300, 850)\n",
    "    \n",
    "    # Account type (introduce drift)\n",
    "    if version == 'v1':\n",
    "        account_types = np.random.choice(\n",
    "            ['Basic', 'Premium', 'Gold'],\n",
    "            num_records,\n",
    "            p=[0.6, 0.3, 0.1]\n",
    "        )\n",
    "    else:\n",
    "        if drift_level == 'high':\n",
    "            account_types = np.random.choice(\n",
    "                ['Basic', 'Premium', 'Gold'],\n",
    "                num_records,\n",
    "                p=[0.4, 0.35, 0.25]\n",
    "            )\n",
    "        elif drift_level == 'medium':\n",
    "            account_types = np.random.choice(\n",
    "                ['Basic', 'Premium', 'Gold'],\n",
    "                num_records,\n",
    "                p=[0.5, 0.35, 0.15]\n",
    "            )\n",
    "        else:\n",
    "            account_types = np.random.choice(\n",
    "                ['Basic', 'Premium', 'Gold'],\n",
    "                num_records,\n",
    "                p=[0.6, 0.3, 0.1]\n",
    "            )\n",
    "    \n",
    "    # Account balance\n",
    "    balances = np.random.exponential(5000, num_records)\n",
    "    balances = np.round(balances, 2)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'customer_id': customer_ids,\n",
    "        'age': ages,\n",
    "        'income': incomes,\n",
    "        'region': regions,\n",
    "        'credit_score': credit_scores,\n",
    "        'account_type': account_types,\n",
    "        'account_balance': balances,\n",
    "        'data_version': version,\n",
    "        'processed_timestamp': base_date\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Customer data generation function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bf22673-3f15-4eff-b2f3-7c0d412336f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product sales data generation function created\n"
     ]
    }
   ],
   "source": [
    "def generate_product_sales_data(num_records, version, drift_level='none'):\n",
    "    \"\"\"\n",
    "    Generate product sales transaction data with optional drift.\n",
    "    \n",
    "    Args:\n",
    "        num_records: Number of transaction records to generate\n",
    "        version: Version identifier\n",
    "        drift_level: Level of drift\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame with sales data\n",
    "    \"\"\"\n",
    "    base_date = datetime.now() - timedelta(days=30 if version == 'v1' else 0)\n",
    "    \n",
    "    transaction_ids = [f\"TXN_{i:08d}\" for i in range(1, num_records + 1)]\n",
    "    \n",
    "    # Product categories (introduce drift)\n",
    "    if version == 'v1':\n",
    "        categories = np.random.choice(\n",
    "            ['Electronics', 'Clothing', 'Home', 'Books', 'Sports'],\n",
    "            num_records,\n",
    "            p=[0.25, 0.25, 0.2, 0.15, 0.15]\n",
    "        )\n",
    "    else:\n",
    "        if drift_level == 'high':\n",
    "            categories = np.random.choice(\n",
    "                ['Electronics', 'Clothing', 'Home', 'Books', 'Sports'],\n",
    "                num_records,\n",
    "                p=[0.35, 0.15, 0.25, 0.1, 0.15]\n",
    "            )\n",
    "        elif drift_level == 'medium':\n",
    "            categories = np.random.choice(\n",
    "                ['Electronics', 'Clothing', 'Home', 'Books', 'Sports'],\n",
    "                num_records,\n",
    "                p=[0.28, 0.22, 0.22, 0.14, 0.14]\n",
    "            )\n",
    "        else:\n",
    "            categories = np.random.choice(\n",
    "                ['Electronics', 'Clothing', 'Home', 'Books', 'Sports'],\n",
    "                num_records,\n",
    "                p=[0.25, 0.25, 0.2, 0.15, 0.15]\n",
    "            )\n",
    "    \n",
    "    # Price distribution (introduce drift)\n",
    "    if version == 'v1':\n",
    "        prices = np.random.gamma(5, 20, num_records)\n",
    "    else:\n",
    "        if drift_level == 'high':\n",
    "            prices = np.random.gamma(6, 25, num_records)\n",
    "        elif drift_level == 'medium':\n",
    "            prices = np.random.gamma(5.5, 22, num_records)\n",
    "        else:\n",
    "            prices = np.random.gamma(5, 20, num_records)\n",
    "    \n",
    "    prices = np.round(prices, 2)\n",
    "    \n",
    "    # Quantity\n",
    "    quantities = np.random.poisson(2, num_records) + 1\n",
    "    \n",
    "    # Revenue\n",
    "    revenues = prices * quantities\n",
    "    \n",
    "    # Discount applied (introduce drift)\n",
    "    if version == 'v1':\n",
    "        discounts = np.random.choice([True, False], num_records, p=[0.3, 0.7])\n",
    "    else:\n",
    "        if drift_level == 'high':\n",
    "            discounts = np.random.choice([True, False], num_records, p=[0.5, 0.5])\n",
    "        else:\n",
    "            discounts = np.random.choice([True, False], num_records, p=[0.3, 0.7])\n",
    "    \n",
    "    # Payment method (introduce drift)\n",
    "    if version == 'v1':\n",
    "        payment_methods = np.random.choice(\n",
    "            ['Credit Card', 'Debit Card', 'PayPal', 'Cash'],\n",
    "            num_records,\n",
    "            p=[0.4, 0.3, 0.2, 0.1]\n",
    "        )\n",
    "    else:\n",
    "        if drift_level == 'high':\n",
    "            payment_methods = np.random.choice(\n",
    "                ['Credit Card', 'Debit Card', 'PayPal', 'Cash'],\n",
    "                num_records,\n",
    "                p=[0.35, 0.25, 0.35, 0.05]\n",
    "            )\n",
    "        else:\n",
    "            payment_methods = np.random.choice(\n",
    "                ['Credit Card', 'Debit Card', 'PayPal', 'Cash'],\n",
    "                num_records,\n",
    "                p=[0.4, 0.3, 0.2, 0.1]\n",
    "            )\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'transaction_id': transaction_ids,\n",
    "        'product_category': categories,\n",
    "        'price': prices,\n",
    "        'quantity': quantities,\n",
    "        'revenue': revenues,\n",
    "        'discount_applied': discounts,\n",
    "        'payment_method': payment_methods,\n",
    "        'data_version': version,\n",
    "        'processed_timestamp': base_date\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Product sales data generation function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2dd8438-086c-474e-b0ac-05ed3dcf8805",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User behavior data generation function created\n"
     ]
    }
   ],
   "source": [
    "def generate_user_behavior_data(num_records, version, drift_level='none'):\n",
    "    \"\"\"\n",
    "    Generate user behavior and engagement data with optional drift.\n",
    "    \n",
    "    Args:\n",
    "        num_records: Number of user event records to generate\n",
    "        version: Version identifier\n",
    "        drift_level: Level of drift\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame with user behavior data\n",
    "    \"\"\"\n",
    "    base_date = datetime.now() - timedelta(days=30 if version == 'v1' else 0)\n",
    "    \n",
    "    user_ids = [f\"USER_{i:07d}\" for i in range(1, num_records + 1)]\n",
    "    \n",
    "    # Session duration in minutes (introduce drift)\n",
    "    if version == 'v1':\n",
    "        session_durations = np.random.exponential(15, num_records)\n",
    "    else:\n",
    "        if drift_level == 'high':\n",
    "            session_durations = np.random.exponential(22, num_records)\n",
    "        elif drift_level == 'medium':\n",
    "            session_durations = np.random.exponential(18, num_records)\n",
    "        else:\n",
    "            session_durations = np.random.exponential(15, num_records)\n",
    "    \n",
    "    session_durations = np.round(session_durations, 2)\n",
    "    \n",
    "    # Pages viewed (introduce drift)\n",
    "    if version == 'v1':\n",
    "        pages_viewed = np.random.poisson(8, num_records)\n",
    "    else:\n",
    "        if drift_level == 'high':\n",
    "            pages_viewed = np.random.poisson(12, num_records)\n",
    "        elif drift_level == 'medium':\n",
    "            pages_viewed = np.random.poisson(10, num_records)\n",
    "        else:\n",
    "            pages_viewed = np.random.poisson(8, num_records)\n",
    "    \n",
    "    # Device type (introduce drift)\n",
    "    if version == 'v1':\n",
    "        devices = np.random.choice(\n",
    "            ['Mobile', 'Desktop', 'Tablet'],\n",
    "            num_records,\n",
    "            p=[0.5, 0.35, 0.15]\n",
    "        )\n",
    "    else:\n",
    "        if drift_level == 'high':\n",
    "            devices = np.random.choice(\n",
    "                ['Mobile', 'Desktop', 'Tablet'],\n",
    "                num_records,\n",
    "                p=[0.65, 0.25, 0.1]\n",
    "            )\n",
    "        elif drift_level == 'medium':\n",
    "            devices = np.random.choice(\n",
    "                ['Mobile', 'Desktop', 'Tablet'],\n",
    "                num_records,\n",
    "                p=[0.57, 0.30, 0.13]\n",
    "            )\n",
    "        else:\n",
    "            devices = np.random.choice(\n",
    "                ['Mobile', 'Desktop', 'Tablet'],\n",
    "                num_records,\n",
    "                p=[0.5, 0.35, 0.15]\n",
    "            )\n",
    "    \n",
    "    # Conversion (introduce drift)\n",
    "    if version == 'v1':\n",
    "        conversions = np.random.choice([True, False], num_records, p=[0.15, 0.85])\n",
    "    else:\n",
    "        if drift_level == 'high':\n",
    "            conversions = np.random.choice([True, False], num_records, p=[0.22, 0.78])\n",
    "        else:\n",
    "            conversions = np.random.choice([True, False], num_records, p=[0.15, 0.85])\n",
    "    \n",
    "    # Bounce rate\n",
    "    bounce_rates = np.random.beta(2, 5, num_records)\n",
    "    bounce_rates = np.round(bounce_rates, 3)\n",
    "    \n",
    "    # Traffic source (introduce drift)\n",
    "    if version == 'v1':\n",
    "        traffic_sources = np.random.choice(\n",
    "            ['Organic', 'Paid', 'Social', 'Direct', 'Referral'],\n",
    "            num_records,\n",
    "            p=[0.3, 0.25, 0.2, 0.15, 0.1]\n",
    "        )\n",
    "    else:\n",
    "        if drift_level == 'high':\n",
    "            traffic_sources = np.random.choice(\n",
    "                ['Organic', 'Paid', 'Social', 'Direct', 'Referral'],\n",
    "                num_records,\n",
    "                p=[0.25, 0.2, 0.35, 0.12, 0.08]\n",
    "            )\n",
    "        else:\n",
    "            traffic_sources = np.random.choice(\n",
    "                ['Organic', 'Paid', 'Social', 'Direct', 'Referral'],\n",
    "                num_records,\n",
    "                p=[0.3, 0.25, 0.2, 0.15, 0.1]\n",
    "            )\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'user_id': user_ids,\n",
    "        'session_duration_minutes': session_durations,\n",
    "        'pages_viewed': pages_viewed,\n",
    "        'device_type': devices,\n",
    "        'conversion': conversions,\n",
    "        'bounce_rate': bounce_rates,\n",
    "        'traffic_source': traffic_sources,\n",
    "        'data_version': version,\n",
    "        'processed_timestamp': base_date\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"User behavior data generation function created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afdfa74e-2f04-495b-b847-93582f4694f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Generate and Save Data to Unity Catalog\n",
    "\n",
    "Generate two versions of each table:\n",
    "- Version 1 (v1): Reference/baseline data\n",
    "- Version 2 (v2): Current data with introduced drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "481b5c3e-c9a7-4aea-88f8-62c4acd95fdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating customer data...\nâœ“ Customer data saved to data_catalog.outputs.customer_data\n  - Version 1: 10000 records\n  - Version 2: 10000 records\n"
     ]
    }
   ],
   "source": [
    "# Generate Customer Data\n",
    "print(\"Generating customer data...\")\n",
    "customer_v1 = generate_customer_data(NUM_CUSTOMERS, 'v1', drift_level='none')\n",
    "customer_v2 = generate_customer_data(NUM_CUSTOMERS, 'v2', drift_level='high')\n",
    "\n",
    "# Combine versions\n",
    "#customer_combined = pd.concat([customer_v1, customer_v2], ignore_index=True)\n",
    "\n",
    "# Convert to Spark DataFrame and save\n",
    "customer_spark_df1 = spark.createDataFrame(customer_v1)\n",
    "customer_spark_df2 = spark.createDataFrame(customer_v2)\n",
    "\n",
    "table_name = f\"{CATALOG_NAME}.{SCHEMA_NAME}.customer_data\"\n",
    "customer_spark_df1.write.mode(\"overwrite\").saveAsTable(table_name)\n",
    "customer_spark_df2.write.mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "print(f\"âœ“ Customer data saved to {table_name}\")\n",
    "print(f\"  - Version 1: {len(customer_v1)} records\")\n",
    "print(f\"  - Version 2: {len(customer_v2)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a942080a-2276-4e13-917a-fec2c6b90f3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating product sales data...\nâœ“ Product sales data saved to data_catalog.outputs.product_sales\n  - Version 1: 50000 records\n  - Version 2: 50000 records\n"
     ]
    }
   ],
   "source": [
    "# Generate Product Sales Data\n",
    "print(\"Generating product sales data...\")\n",
    "sales_v1 = generate_product_sales_data(NUM_TRANSACTIONS, 'v1', drift_level='none')\n",
    "sales_v2 = generate_product_sales_data(NUM_TRANSACTIONS, 'v2', drift_level='high')\n",
    "\n",
    "# Combine versions\n",
    "#sales_combined = pd.concat([sales_v1, sales_v2], ignore_index=True)\n",
    "\n",
    "# Convert to Spark DataFrame and save\n",
    "sales_spark_df1 = spark.createDataFrame(sales_v1)\n",
    "sales_spark_df2 = spark.createDataFrame(sales_v2)\n",
    "\n",
    "table_name = f\"{CATALOG_NAME}.{SCHEMA_NAME}.product_sales\"\n",
    "sales_spark_df1.write.mode(\"overwrite\").saveAsTable(table_name)\n",
    "sales_spark_df2.write.mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "print(f\"âœ“ Product sales data saved to {table_name}\")\n",
    "print(f\"  - Version 1: {len(sales_v1)} records\")\n",
    "print(f\"  - Version 2: {len(sales_v2)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56192f1d-c2dc-41a5-b667-98e21fc201d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating user behavior data...\nâœ“ User behavior data saved to data_catalog.outputs.user_behavior\n  - Version 1: 30000 records\n  - Version 2: 30000 records\n"
     ]
    }
   ],
   "source": [
    "# Generate User Behavior Data\n",
    "print(\"Generating user behavior data...\")\n",
    "behavior_v1 = generate_user_behavior_data(NUM_USER_EVENTS, 'v1', drift_level='none')\n",
    "behavior_v2 = generate_user_behavior_data(NUM_USER_EVENTS, 'v2', drift_level='high')\n",
    "\n",
    "# Combine versions\n",
    "behavior_combined = pd.concat([behavior_v1, behavior_v2], ignore_index=True)\n",
    "\n",
    "# Convert to Spark DataFrame and save\n",
    "behavior_spark_df1 = spark.createDataFrame(behavior_v1)\n",
    "behavior_spark_df2 = spark.createDataFrame(behavior_v2)\n",
    "\n",
    "table_name = f\"{CATALOG_NAME}.{SCHEMA_NAME}.user_behavior\"\n",
    "behavior_spark_df1.write.mode(\"overwrite\").saveAsTable(table_name)\n",
    "behavior_spark_df2.write.mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "print(f\"âœ“ User behavior data saved to {table_name}\")\n",
    "print(f\"  - Version 1: {len(behavior_v1)} records\")\n",
    "print(f\"  - Version 2: {len(behavior_v2)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5481e5b5-7278-4879-bcff-6e0b040cdddb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Verify Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ead9c1a5-dd08-4981-a15d-8d3039a3861a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying created tables...\n\nTables in catalog:\n  - customer_data\n  - product_sales\n  - user_behavior\n\n================================================================================\nSample Customer Data (v2):\n================================================================================\n+-----------+---+---------+------+------------+------------+---------------+------------+--------------------+\n|customer_id|age|   income|region|credit_score|account_type|account_balance|data_version| processed_timestamp|\n+-----------+---+---------+------+------------+------------+---------------+------------+--------------------+\n|CUST_001251| 36| 84731.33| North|         655|        Gold|        2766.51|          v2|2026-01-19 16:20:...|\n|CUST_001252| 43|  15048.8| South|         682|       Basic|         951.49|          v2|2026-01-19 16:20:...|\n|CUST_001253| 33|120593.68|  East|         634|     Premium|        4913.81|          v2|2026-01-19 16:20:...|\n|CUST_001254| 18| 31117.31|  West|         718|       Basic|        1899.18|          v2|2026-01-19 16:20:...|\n|CUST_001255| 35|132706.51| North|         557|     Premium|        2159.24|          v2|2026-01-19 16:20:...|\n+-----------+---+---------+------+------------+------------+---------------+------------+--------------------+\n\n\n================================================================================\nSample Product Sales Data (v2):\n================================================================================\n+--------------+----------------+------+--------+-------+----------------+--------------+------------+--------------------+\n|transaction_id|product_category| price|quantity|revenue|discount_applied|payment_method|data_version| processed_timestamp|\n+--------------+----------------+------+--------+-------+----------------+--------------+------------+--------------------+\n|  TXN_00037501|        Clothing|132.82|       2| 265.64|            true|    Debit Card|          v2|2026-01-19 16:21:...|\n|  TXN_00037502|           Books|157.26|       2| 314.52|            true|    Debit Card|          v2|2026-01-19 16:21:...|\n|  TXN_00037503|     Electronics|  97.7|       3|  293.1|            true|        PayPal|          v2|2026-01-19 16:21:...|\n|  TXN_00037504|          Sports|123.65|       2|  247.3|            true|   Credit Card|          v2|2026-01-19 16:21:...|\n|  TXN_00037505|     Electronics| 83.32|       1|  83.32|           false|        PayPal|          v2|2026-01-19 16:21:...|\n+--------------+----------------+------+--------+-------+----------------+--------------+------------+--------------------+\n\n\n================================================================================\nSample User Behavior Data (v2):\n================================================================================\n+------------+------------------------+------------+-----------+----------+-----------+--------------+------------+--------------------+\n|     user_id|session_duration_minutes|pages_viewed|device_type|conversion|bounce_rate|traffic_source|data_version| processed_timestamp|\n+------------+------------------------+------------+-----------+----------+-----------+--------------+------------+--------------------+\n|USER_0022501|                    16.7|          16|     Mobile|     false|      0.052|       Organic|          v2|2026-01-19 16:21:...|\n|USER_0022502|                    5.31|           9|     Mobile|     false|      0.469|      Referral|          v2|2026-01-19 16:21:...|\n|USER_0022503|                   38.64|          12|     Mobile|     false|      0.552|          Paid|          v2|2026-01-19 16:21:...|\n|USER_0022504|                   55.96|           8|    Desktop|     false|      0.251|       Organic|          v2|2026-01-19 16:21:...|\n|USER_0022505|                   54.03|          12|     Mobile|     false|      0.124|        Social|          v2|2026-01-19 16:21:...|\n+------------+------------------------+------------+-----------+----------+-----------+--------------+------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Verify tables exist\n",
    "print(\"Verifying created tables...\")\n",
    "tables = spark.sql(f\"SHOW TABLES IN {CATALOG_NAME}.{SCHEMA_NAME}\").collect()\n",
    "\n",
    "print(\"\\nTables in catalog:\")\n",
    "for table in tables:\n",
    "    print(f\"  - {table.tableName}\")\n",
    "\n",
    "# Show sample data from each table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample Customer Data (v2):\")\n",
    "print(\"=\"*80)\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT * FROM {CATALOG_NAME}.{SCHEMA_NAME}.customer_data \n",
    "    WHERE data_version = 'v2' \n",
    "    LIMIT 5\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample Product Sales Data (v2):\")\n",
    "print(\"=\"*80)\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT * FROM {CATALOG_NAME}.{SCHEMA_NAME}.product_sales \n",
    "    WHERE data_version = 'v2' \n",
    "    LIMIT 5\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample User Behavior Data (v2):\")\n",
    "print(\"=\"*80)\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT * FROM {CATALOG_NAME}.{SCHEMA_NAME}.user_behavior \n",
    "    WHERE data_version = 'v2' \n",
    "    LIMIT 5\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_generate_dummy_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}