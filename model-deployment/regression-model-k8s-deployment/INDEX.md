# Project File Index

Quick reference for where things are and what they do.

## ğŸ“‚ Top-Level Files

| File | Purpose |
|------|---------|
| `README.md` | Start here â€” overview and quick start |
| `SETUP_GUIDE.md` | Step-by-step local setup |
| `ARCHITECTURE.md` | System design and data flow |
| `MINIKUBE_SETUP_GUIDE.txt` | Detailed Minikube setup |
| `ECR_PUSH_GUIDE.txt` | Push Docker image to AWS ECR |
| `requirements.txt` | Python dependencies (development) |
| `config/model_config.yaml` | Central configuration (algorithms, parameters) |

## ğŸ“ Main Directories

### `/notebooks` â€” Training Pipeline
Run these in order (local, via Jupyter):

1. **01_data_generation.ipynb** â€” Generates synthetic data â†’ `../output/data/training_data.csv`
2. **02_feature_engineering.ipynb** â€” Splits and scales â†’ `../output/feature_engineering/*.csv`
3. **03_model_training.ipynb** â€” Trains model â†’ `../output/modeling/regression_model.pkl`, logs to `../output/mlruns/`
4. **04_inference.ipynb** â€” Test predictions locally or via API

### `/src` â€” Reusable Code
- **config.py** â€” Load YAML configuration
- **utils.py** â€” Utilities: splitting, scaling, metrics
- **model.py** â€” Model building and MLflow

(Used by notebooks and Docker app)

### `/docker` â€” API Server
- **app.py** â€” FastAPI inference server
- **Dockerfile** â€” Container definition
- **requirements.txt** â€” Container Python packages
- **docker-compose.yml** â€” Run with volume mounts
- **run.sh** / **run.ps1** â€” Quick build/run scripts

### `/k8s` â€” Kubernetes (Minikube)
- **deployment.yaml** â€” Pod definition
- **service.yaml** â€” Service exposes port 30080

### `/scripts` â€” Automation
- **k8s_deploy_minikube.ps1** / **.sh** â€” Deploy to Minikube
- **smoke_test_minikube.ps1** â€” End-to-end test
- **ecr_push.ps1** / **.sh** â€” Push to AWS ECR

### `/tests` â€” Testing
- **test_api.py** â€” Test API endpoints
  - Usage: `python tests/test_api.py --url http://localhost:5000`

### `/tools` â€” Helpers
- **quickstart.py** â€” Check dependencies and show workflow
  - Usage: `python tools/quickstart.py`

### `/output` â€” Generated Artifacts (created during notebook runs)
```
output/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ training_data.csv
â”œâ”€â”€ feature_engineering/
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ val.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ feature_names.json
â”œâ”€â”€ modeling/
â”‚   â”œâ”€â”€ regression_model.pkl
â”‚   â”œâ”€â”€ model_params.json
â”‚   â””â”€â”€ feature_names.json
â””â”€â”€ mlruns/
    â””â”€â”€ (MLflow run directories)
```

## ğŸ”„ Data & Execution Flow

```
Local Development (Jupyter)
  01_data_generation.ipynb
    â†“
  output/data/training_data.csv
    â†“
  02_feature_engineering.ipynb
    â†“
  output/feature_engineering/{train,val,test}.csv
    â†“
  03_model_training.ipynb
    â†“
  output/modeling/regression_model.pkl
  output/mlruns/ (MLflow logs)

Docker & Kubernetes
  docker/app.py reads output/modeling/*.pkl
    â†“
  Serves: http://localhost:5000/health, /predict, etc.
    â†“
  (Optional) Deploy to Minikube/K8s
  Serves: http://localhost:30080/health, /predict, etc.
```

## ğŸ’¡ Quick Answers

**Where to change the model algorithm?**
â†’ Edit `config/model_config.yaml`, section `model_training.algorithm`

**Where to change data generation?**
â†’ Edit `config/model_config.yaml`, section `data_generation`

**Where to add new API endpoints?**
â†’ Edit `docker/app.py`, add new `@app.get()` or `@app.post()` function

**Where to add utilities?**
â†’ Edit `src/utils.py`

**How to test locally?**
â†’ `python tests/test_api.py --url http://localhost:5000` (after Docker is running)

**How to deploy to Minikube?**
â†’ Follow [MINIKUBE_SETUP_GUIDE.txt](MINIKUBE_SETUP_GUIDE.txt) or run `scripts/k8s_deploy_minikube.ps1` (Windows)

**How to push to ECR?**
â†’ Follow [ECR_PUSH_GUIDE.txt](ECR_PUSH_GUIDE.txt)

## ğŸ“š Reading Order for New Users

1. **README.md** â€” Understand what this project does
2. **SETUP_GUIDE.md** â€” Get everything installed
3. **ARCHITECTURE.md** â€” Learn how pieces fit together
4. **config/model_config.yaml** â€” See what's configurable
5. **notebooks/** â€” Study the code in order (01 â†’ 04)
6. **docker/app.py** â€” Understand the API server
7. **MINIKUBE_SETUP_GUIDE.txt** â€” When ready to deploy to K8s

## ğŸ¯ Common Tasks

### Run the Full Pipeline Locally
```bash
pip install -r docker/requirements.txt
pip install jupyter
jupyter notebook
# Run notebooks 01, 02, 03 in order
cd docker && docker-compose up -d
python tests/test_api.py
```

### Deploy to Minikube
```bash
minikube start --driver=docker --cpus=2 --memory=4096
minikube mount $(pwd)/output:/tmp/ml-output  # Terminal 1
./scripts/k8s_deploy_minikube.sh               # Terminal 2
python tests/test_api.py --url http://localhost:30080
```

### Push to ECR and Deploy
```bash
export PUSH_TO_ECR=true
export ECR_REGISTRY=123456789012.dkr.ecr.us-east-1.amazonaws.com
./scripts/ecr_push.ps1

# Update k8s/deployment.yaml with ECR image URL
# Deploy to your cluster
```

## ğŸ—‚ï¸ What to Edit vs. What NOT to Edit

**Edit these (usually):**
- `config/model_config.yaml` â€” Change algorithm, parameters, data size
- `notebooks/*.ipynb` â€” Custom data processing, features
- `docker/app.py` â€” Add endpoints, change inference logic
- `k8s/deployment.yaml` â€” Replicas, resource limits (for cloud)

**Don't edit (usually):**
- `src/config.py` â€” Edit config.yaml instead
- `src/utils.py` â€” Unless adding new utilities
- `docker/Dockerfile` â€” Unless adding packages
- `.gitignore` â€” Unless excluding new file types

## ğŸ“¦ What to Commit to Git

**Commit:**
- Source code (`src/`, `notebooks/`, `docker/`, `k8s/`, `scripts/`, `tools/`, `tests/`)
- Configuration (`config/model_config.yaml`)
- Documentation (.md files, .txt guides)
- `requirements.txt`

**Don't commit:**
- `output/` directory (data, models, MLflow runs)
- `.env` or credentials files
- `__pycache__`, `.pyc` files
- `venv/` or virtual environment

(Covered by `.gitignore`)

---